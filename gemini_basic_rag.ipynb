{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6077937",
   "metadata": {},
   "source": [
    "## PDF Yüklemesinin Gerçekleştirilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3cb40dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"attentionisallyouneed.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f656b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18837696",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "168d2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59eb7326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents after chunking: 52\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of documents after chunking: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1992297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attentionisallyouneed.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2d3bb",
   "metadata": {},
   "source": [
    "## Google GenAI Embeddings'i Kullanarak Embedding oluşturma işlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c73908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e57b54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5995b17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.020920176, 0.009755219, 0.004780903, -0.059421252, 0.0050828396]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "vector = embeddings.embed_query(\"Hello, world!\")\n",
    "vector[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0c1f9",
   "metadata": {},
   "source": [
    "## ChromadB üzerine Kayıt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5945970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "defa5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f5379eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type = \"similarity\", search_kwargs={\"k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "453ec1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is encoder?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ee7f4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3613aa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer uses multi-head attention in three different ways:\n",
      "• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\n",
      "and the memory keys and values come from the output of the encoder. This allows every\n",
      "position in the decoder to attend over all positions in the input sequence. This mimics the\n",
      "typical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n",
      "[38, 2, 9].\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\n",
      "and queries come from the same place, in this case, the output of the previous layer in the\n",
      "encoder. Each position in the encoder can attend to all positions in the previous layer of the\n",
      "encoder.\n",
      "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\n",
      "all positions in the decoder up to and including that position. We need to prevent leftward\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[5].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd7b87",
   "metadata": {},
   "source": [
    "## Google Gemini API Yapısını Kullanarak LLM Tetikleme İşlemi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b96183",
   "metadata": {},
   "source": [
    "https://docs.langchain.com/oss/python/integrations/chat/google_generative_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c9a9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0.3,  # Gemini 3.0+ defaults to 1.0\n",
    "    max_tokens=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba6cbf0",
   "metadata": {},
   "source": [
    "https://reference.langchain.com/python/langchain_core/prompts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72301c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains import create_retrieval_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fa29be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a assistant for question answering tasks. \"\n",
    "    \"Use the following context to provide accurate and concise answers.\"\n",
    "    \"If you don't know the answer, just say you don't know. \" \n",
    "    \"Use three sentences maximum.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"  # context will be filled in with retrieved documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "313acdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"Answer the question based on the context above: {input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afcf54",
   "metadata": {},
   "source": [
    "## Soru Cevap Zincirini Oluşturma (LLM+PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4fec494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ff260",
   "metadata": {},
   "source": [
    "## RAG Zinciri OLUŞTURMA (rag+ llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34d8ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(retriever, question_answering_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bbffd2",
   "metadata": {},
   "source": [
    "## Kullanıcı Sorgusunu Çalıştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca98b733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEVAP:\n",
      "The Transformer architecture relies entirely on an attention mechanism, eschewing recurrence to draw global dependencies between input and output. It uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder has six identical layers, each with a multi-head self-attention mechanism and a feed-forward network, with residual connections and layer normalization applied.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Explain the transformer architecture.\"})\n",
    "\n",
    "print(\"CEVAP:\")\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
